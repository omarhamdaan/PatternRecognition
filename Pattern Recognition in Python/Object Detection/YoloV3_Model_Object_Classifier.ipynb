{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81b2f596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "# define the minimum confidence (to filter weak detections), \n",
    "# Non-Maximum Suppression (NMS) threshold, and the green color\n",
    "confidence_thresh = 0.5\n",
    "NMS_thresh = 0.3\n",
    "green = (0, 255, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f885bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the class labels the model was trained on\n",
    "classes_path = \"coco.names\"\n",
    "with open(classes_path, \"r\") as f:\n",
    "    classes = f.read().strip().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a68731a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n"
     ]
    }
   ],
   "source": [
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbd5ea34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the minimum confidence (to filter weak detections), \n",
    "# Non-Maximum Suppression (NMS) threshold, and the green color\n",
    "confidence_thresh = 0.5\n",
    "NMS_thresh = 0.3\n",
    "green = (0, 255, 0)\n",
    "\n",
    "# Initialize the video capture object\n",
    "video_cap = cv2.VideoCapture(\"road_trafifc.mp4\")\n",
    "\n",
    "\n",
    "    \n",
    "# load the configuration and weights from disk\n",
    "yolo_config = \"yolov3.cfg\"\n",
    "yolo_weights = \"yolov3.weights\"\n",
    "\n",
    "# load the pre-trained YOLOv3 network\n",
    "\n",
    "net = cv2.dnn.readNetFromDarknet(yolo_config, yolo_weights)\n",
    "# net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "# net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)\n",
    "\n",
    "# # Get the name of all the layers in the network\n",
    "# layer_names = net.getLayerNames()\n",
    "# output_layers =[]\n",
    "# print(layer_names)\n",
    "# Get the names of the output layers\n",
    "# output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "# print(net.getUnconnectedOutLayers())\n",
    "# output_layers.append(layer_names[200]) \n",
    "# output_layers.append(layer_names[227]) \n",
    "# output_layers.append(layer_names[254]) \n",
    "# print(layer_names)\n",
    "output_layers = ['yolo_82', 'yolo_94', 'yolo_106']\n",
    "# output_layers = ['yolo_82']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a46778f",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_cap = cv2.VideoCapture(\"road_trafifc.mp4\")\n",
    "while True:\n",
    "    # start time to compute the fps\n",
    "    start = time.time()\n",
    "    # read the video frame\n",
    "    success, frame = video_cap.read()\n",
    "  \n",
    "    # if there are no more frames to show, break the loop\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    # # get the frame dimensions\n",
    "    h = frame.shape[0]\n",
    "    w = frame.shape[1]\n",
    "\n",
    "    # create a blob from the frame\n",
    "    blob = cv2.dnn.blobFromImage(\n",
    "        frame, 1 / 255, (416, 416), swapRB=True, crop=False)\n",
    "    # pass the blog through the network and get the output predictions\n",
    "    net.setInput(blob)\n",
    "    outputs = net.forward(output_layers)\n",
    "    \n",
    "    # create empty lists for storing the bounding boxes, confidences, and class IDs\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    class_ids = []\n",
    "\n",
    "    # loop over the output predictions\n",
    "    for output in outputs:\n",
    "        # loop over the detections\n",
    "        for detection in output:\n",
    "            # get the class ID and confidence of the dected object\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence  = scores[class_id]\n",
    "\n",
    "            # filter out weak detections by keeping only those with a confidence \n",
    "            # above the minimum confidence threshold (0.5 in this case).\n",
    "            if confidence > confidence_thresh:\n",
    "                # perform element-wise multiplication to get\n",
    "                # the coordinates of the bounding box\n",
    "                box = [int(a * b) for a, b in zip(detection[0:4], [w, h, w, h])]\n",
    "                center_x, center_y, width, height = box\n",
    "\n",
    "                # get the top-left corner of the bounding box\n",
    "                x = int(center_x - (width / 2))\n",
    "                y = int(center_y - (height / 2))\n",
    "\n",
    "                # append the bounding box, confidence, and class ID to their respective lists\n",
    "                class_ids.append(class_id)\n",
    "                confidences.append(float(confidence))\n",
    "                boxes.append([x, y, width, height])\n",
    "    # apply non-maximum suppression to remove weak bounding boxes that overlap with others.\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, confidence_thresh, NMS_thresh)\n",
    "    indices = indices.flatten()\n",
    "\n",
    "    for i in indices:\n",
    "        (x, y, w, h) = boxes[i][0], boxes[i][1], boxes[i][2], boxes[i][3]\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), green, 2)\n",
    "        text = f\"{classes[class_ids[i]]}: {confidences[i] * 100:.2f}%\"\n",
    "        cv2.putText(frame, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, green, 1)\n",
    "\n",
    "    # end time to compute the fps\n",
    "    end = time.time()\n",
    "    # calculate the frame per second and draw it on the frame\n",
    "    fps = f\"FPS: {1 / (end - start):.2f}\"\n",
    "    cv2.putText(frame, fps, (50, 50),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 1)\n",
    "\n",
    "    # display the frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    # if the 'q' key is pressed, stop the loop\n",
    "    if cv2.waitKey(30) == ord(\"q\"): \n",
    "        break\n",
    "\n",
    "# release the video capture object\n",
    "video_cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d4c6c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad073a43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
